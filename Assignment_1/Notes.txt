    Notes for Time:

Times (measured on Gantenbein):
-> Compiled with -O0:
    between 2.378s and 2.459s    
-> Compiled with -O1:
    between 0.265s and 0.281s
-> Compiled with -O2:
    between 939ns and 3336ns
-> Compiled with -O3:
    between 946ns and 3000ns
-> Compiled with -Os:
    between 0.268s and 0.270s
-> Compiled with -Og:
    between 0.535s and 0.552s

    Notes to time assembly code:
the higher the optimization level, the smaller the assembly code
which makes sense but is also an indication that it is harder to 
find a bug in the optimized assembly code


#### #### #### #### #### #### #### #### #### #### #### #### #### #### #### 


    Notes for Inlining:
[Benchmarked the 3 variants with hyperfine on Gantenbein]
mainfile
    mean: 0.3 - 0.5 ms but quite large deviation of +/- 1.0 ms
    min ... max: 0.0 ms ... 3.5 ms

separatefile
    mean: 0.4 - 0.5 ms but again with +/- 1.0 ms
    min ... max: 0.0 ms ... 3.5 ms

inlined
    mean: 0.4 - 0.5 ms also +/- 1.0 ms
    min ... max: 0.0 ms ... 3.6 ms

I benchmarked both during a crowded Computer Lab session and on a different time 
but was not really able to get any difference at all (or only very little difference).


using nm to find examine the executables mul_cpx_mainfile and mul_cpx_separatefile:
nm mul_cpx_mainfile:
    I can find the method name of "mul_cpx" in the output as well as the "main" method
    but nothing for "mul_cpx_mainfile"
nm mul_cpx_separatefile:
    I find again the method name "mul_cpx" as well as "main" 
    but again nothing for "mul_cpx_separatefile"

I compared the outputs of nm on both executables and they are (nearly) exactly the same except of some of the numbers in front of the symbols.



#### #### #### #### #### #### #### #### #### #### #### #### #### #### #### 


    Notes for Locality:

Benchmarking both with timespec_get time on Gantenbein (-O2):
row sum: ~1.7ms
col sum: ~2.0ms with larger deviations ranging from 1.6ms up to 3.3
    which makes sense since we store the data in row order

    --> Reimplement slower (column) summation...
I improved the efficiency by iterating in the same way as in the rows_sum so I can
use the data-locality. I have to jump to different sums[j] all the time but they are
also stored sequentially so this is not really a problem.

    achieved Timing - Improvement:
col2 sum: ~ 0.85ms
so we are even faster than in the row sum. This surprised me a little bit and after 
comparing the code, the only difference is that the row_sum sums first into a local variable
before writing this sum into the sum array. It seems that writing directly to the array 
is more efficient.


    Notes on -O0 compilation:
Running the un-optimized program results in nearly the same execution time for the given
row_sums and col_sums implementations. However, my improved version is notably faster than
the row_sums implementation which surprised me. 
Since the only real difference is the omission of the local sum calculation and instead writing directly to the given sum-array, this has to be the problem here.
